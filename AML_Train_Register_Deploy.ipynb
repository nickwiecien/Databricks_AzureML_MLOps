{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29719eb0-fe62-448a-94d3-e7b9a48204f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Azure Databricks / Azure Machine Learning Sample - Model Training & Deployment Staging\n",
    "\n",
    "Sample notebook showcasing how to train an ML model in Azure Databricks and log/register in a target Azure Machine Learning workspace after performing a champion vs. challenger model evaluation. Further, this notebook contains sample code for deploying your newly trained model to a Managed Online Endpoint. The logic here will identify whether there is currently a model deployed, and if so will update the unoccupied blue/green spot, run a test, and automatically mirror 20% of traffic to the new endpoint.\n",
    "\n",
    "This routine builds a new regression model around the Diabetes Dataset which is available as part of the Scikit-Learn library, and can be adapted to support training building upon existing datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "619ba598-2b92-440f-8d1d-4b85f666f69f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4cfd4ef-2cd5-4373-806d-92a33d85dc4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import SparkSession  \n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, DoubleType  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import neighbors\n",
    "from mlflow.deployments import get_deploy_client\n",
    "import json\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.ai.ml.entities import Environment, ManagedOnlineDeployment, CodeConfiguration, TargetUtilizationScaleSettings\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7903acb-cdd4-491a-a8e8-843e9370af2d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Parse arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "056187ee-8977-4889-b63b-c374099b9982",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "subscription_id = dbutils.widgets.get('subscription_id')\n",
    "resource_group = dbutils.widgets.get('resource_group')\n",
    "workspace = dbutils.widgets.get('workspace')\n",
    "\n",
    "model_name = dbutils.widgets.get('model_name')\n",
    "endpoint_name = dbutils.widgets.get('endpoint_name')\n",
    "endpoint_description = dbutils.widgets.get('endpoint_description')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3acda06-f7b1-42ed-8c17-395c1958be91",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Model training helper functions\n",
    "\n",
    "Collection of functions to support model training, testing, and registration. These functions can be extended to support different types of ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d90cc900-a39b-4c1e-8068-ec375f6682bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_data_to_delta_table(path='dbfs:/tmp/gold-data/diabetes-features'):\n",
    "    \"\"\"\n",
    "    This function loads the diabetes dataset, converts it to a Pandas DataFrame, and writes it to a Delta table.\n",
    "\n",
    "    Args:  \n",
    "        path (str, optional): The path where the Delta table will be saved. Defaults to 'dbfs:/tmp/gold-data/diabetes-features'.  \n",
    "\n",
    "    Returns:  \n",
    "        None  \n",
    "    \"\"\"  \n",
    "    from delta.tables import DeltaTable\n",
    "    from sklearn.datasets import load_diabetes\n",
    "    import pandas as pd\n",
    "    from pyspark.sql import SparkSession\n",
    "    diabetes = load_diabetes()\n",
    "    \n",
    "    # Load the diabetes dataset  \n",
    "    diabetes = load_diabetes()\n",
    "    \n",
    "    # Convert the dataset to a Pandas dataframe  \n",
    "    df = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)  \n",
    "    df['target'] = diabetes.target  \n",
    "     \n",
    "    # Create a Delta table from the Pandas dataframe  \n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    spark_df.write.format('delta').mode('overwrite').save(path)  \n",
    "    print(f\"Data added to delta table at {path}\")\n",
    "    \n",
    "    \n",
    "def get_data_from_delta_table(path='dbfs:/tmp/gold-data/diabetes-features'):\n",
    "    \"\"\"\n",
    "    This function reads data from a Delta table and returns it as a Pandas DataFrame.\n",
    "\n",
    "    Args:  \n",
    "        path (str, optional): The path to the Delta table to be read. Defaults to 'dbfs:/tmp/gold-data/diabetes-features'.  \n",
    "\n",
    "    Returns:  \n",
    "        pandas_df (pd.DataFrame): The data from the Delta table as a Pandas DataFrame.  \n",
    "    \"\"\"  \n",
    "    import pandas as pd\n",
    "    from pyspark.sql import SparkSession\n",
    "    delta_data = spark.read.format(\"delta\").load(path)  \n",
    "    pandas_df = delta_data.toPandas()\n",
    "    print(f\"Loading data from delta table at {path}\")\n",
    "    return pandas_df\n",
    "\n",
    "def get_aml_client(subscription_id, resource_group, workspace):\n",
    "    \"\"\"\n",
    "    This function establishes a connection to an Azure Machine Learning (AML) workspace using a service principal.\n",
    "    It retrieves the tenant ID, client ID, and client secret from a Databricks secret scope and returns an AML client object.\n",
    "\n",
    "    Args:  \n",
    "        subscription_id (str): The Azure subscription ID.  \n",
    "        resource_group (str): The Azure resource group name.  \n",
    "        workspace (str): The Azure Machine Learning workspace name.  \n",
    "\n",
    "    Returns:  \n",
    "        ml_client (azure.ml.core.client.MLClient): An Azure ML client object with an established connection to the specified AML workspace.  \n",
    "    \"\"\"  \n",
    "    from azure.identity import ClientSecretCredential, DefaultAzureCredential\n",
    "    import os\n",
    "\n",
    "    tenant_id = dbutils.secrets.get(scope=\"amlsecretscope\",key=\"tenantid\")\n",
    "    client_id = dbutils.secrets.get(scope=\"amlsecretscope\",key=\"clientid\")\n",
    "    client_secret = dbutils.secrets.get(scope=\"amlsecretscope\",key=\"clientsecret\")\n",
    "    \n",
    "    os.environ[\"AZURE_TENANT_ID\"] = tenant_id\n",
    "    os.environ[\"AZURE_CLIENT_ID\"] = client_id\n",
    "    os.environ[\"AZURE_CLIENT_SECRET\"] = client_secret\n",
    "\n",
    "    credential = ClientSecretCredential(tenant_id, client_id, client_secret)\n",
    "\n",
    "    ml_client = MLClient(\n",
    "        credential, subscription_id, resource_group, workspace\n",
    "    )\n",
    "    print(\"Establishing connection to Azure ML workspace\")\n",
    "    return ml_client\n",
    "    \n",
    "\n",
    "def get_aml_mlflow_tracking_uri(ml_client):\n",
    "    \"\"\"\n",
    "    This function retrieves the MLflow tracking URI for an Azure Machine Learning workspace.\n",
    "\n",
    "    Args:  \n",
    "        ml_client (object): The ml_client which references the target Azure Machine Learning workspace.  \n",
    "\n",
    "    Returns:  \n",
    "        tracking_uri (str): The MLflow tracking URI associated with the Azure Machine Learning workspace.  \n",
    "    \"\"\"  \n",
    "    \n",
    "    ws = ml_client.workspaces.get(workspace)\n",
    "    return ws.mlflow_tracking_uri\n",
    "\n",
    "def split_train_test_data(pandas_df, training_percent=0.8):\n",
    "    \"\"\"\n",
    "    This function splits a Pandas DataFrame into training and testing datasets using the specified training percentage.\n",
    "\n",
    "    Args:  \n",
    "        pandas_df (pd.DataFrame): The input Pandas DataFrame to be split.  \n",
    "        training_percent (float, optional): The percentage of data to be used for training. Defaults to 0.8.  \n",
    "\n",
    "    Returns:  \n",
    "        train_df (pd.DataFrame): The training dataset as a Pandas DataFrame.  \n",
    "        test_df (pd.DataFrame): The testing dataset as a Pandas DataFrame.  \n",
    "    \"\"\"  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_df, test_df = train_test_split(pandas_df, test_size = 1.0 - training_percent)\n",
    "    print('Splitting data into train/test subsets')\n",
    "    return train_df, test_df\n",
    "    \n",
    "def train_regression_model(experiment_name, run_name, training_data, testing_data, target, tracking_uri):\n",
    "    \"\"\"\n",
    "    This function trains a regression model using GradientBoostingRegressor and logs the run using MLflow.\n",
    "\n",
    "    Args:  \n",
    "        experiment_name (str): The name of the MLflow experiment.  \n",
    "        run_name (str): The name of the MLflow run.  \n",
    "        training_data (pd.DataFrame): The training dataset as a Pandas DataFrame.  \n",
    "        testing_data (pd.DataFrame): The testing dataset as a Pandas DataFrame.  \n",
    "        target (str): The name of the target variable in the datasets.  \n",
    "        tracking_uri (str): The MLflow tracking URI.  \n",
    "\n",
    "    Returns:  \n",
    "        run_id (str): The MLflow run ID for the trained model.  \n",
    "    \"\"\"  \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn import preprocessing\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    \n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    X_train = training_data.drop(columns=[target])\n",
    "    X_test = testing_data.drop(columns=[target])\n",
    "    y_train = training_data[target]\n",
    "    y_test = testing_data[target]\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "\n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        model = GradientBoostingRegressor()\n",
    "        pipeline = Pipeline([('transformer', scaler), ('estimator', model)])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        print(f\"Training and logging regression model. {run_id}\")\n",
    "    \n",
    "    return run_id\n",
    "\n",
    "def evaluate_challenger_model(run_id, model_name, test_df, target):\n",
    "    \"\"\"\n",
    "    This function evaluates a challenger model against the current champion model using root mean squared error (RMSE).\n",
    "    The challenger model is considered better if its RMSE is lower than or equal to the champion model's RMSE. The function\n",
    "    also prints the RMSE values of both models for comparison.\n",
    "\n",
    "    Args:  \n",
    "        run_id (str): The MLflow run ID of the challenger model.  \n",
    "        model_name (str): The name of the champion model registered in the MLflow model registry.  \n",
    "        test_df (pd.DataFrame): The testing dataset as a Pandas DataFrame.  \n",
    "        target (str): The name of the target variable in the test dataset.  \n",
    "\n",
    "    Returns:  \n",
    "        bool: True if the challenger model's RMSE is lower than or equal to the champion model's RMSE, False otherwise.  \n",
    "    \"\"\"  \n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    try:\n",
    "        champion_model = mlflow.sklearn.load_model(f\"models:/{model_name}/latest\")\n",
    "        challenger_model = mlflow.sklearn.load_model(f\"runs:/{run_id}/model\")\n",
    "        \n",
    "        X_test = test_df.drop(columns=[target])\n",
    "        y_test = test_df[[target]]\n",
    "        \n",
    "        champion_preds = champion_model.predict(X_test)\n",
    "        challenger_preds = challenger_model.predict(X_test)\n",
    "        \n",
    "        champion_rmse = mean_squared_error(y_test, champion_preds, squared=False)\n",
    "        challenger_rmse = mean_squared_error(y_test, challenger_preds, squared=False)\n",
    "        \n",
    "        print(\"Running model evaluation (champion vs. challenger)\")\n",
    "        print(\"Challenger: \" + str(challenger_rmse))\n",
    "        print(\"Champion: \" + str(champion_rmse))\n",
    "        \n",
    "        # By default register each new model (DEMO ONLY)\n",
    "#         if challenger_rmse <= champion_rmse:\n",
    "#             return True\n",
    "#         else:\n",
    "#             return False\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return True\n",
    "    \n",
    "    return True\n",
    "\n",
    "def register_challenger_model(run_id, model_name):\n",
    "    \"\"\"\n",
    "    Registers a new version of a machine learning model to the MLflow registry. \n",
    "\n",
    "    This function registers a new version of a model to the MLflow registry by providing the run_id and model_name. It prints the registered model's version and returns the result object. \n",
    "\n",
    "    Args:\n",
    "    run_id (str): The unique identifier of the MLflow run containing the model.\n",
    "    model_name (str): The name of the model to be registered. \n",
    "\n",
    "    Returns:\n",
    "    result (mlflow.entities.model_registry.RegisteredModel): An object containing information about the registered model and its version. \n",
    "\n",
    "    Example:\n",
    "    >>> run_id = \"1234567890abcdef\"\n",
    "    >>> model_name = \"my_model\"\n",
    "    >>> register_challenger_model(run_id, model_name)\n",
    "    Registering new version of my_model. Version: 1\n",
    "    <mlflow.entities.model_registry.RegisteredModel object at 0x7f8c9d8e1310>\n",
    "    \"\"\"\n",
    "    result = mlflow.register_model(f\"runs:/{run_id}/model\", model_name)\n",
    "    print(f\"Registering new version of {model_name}. Version: {str(result.version)}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3aea4d2-84ca-4d65-957d-06a3d9e96a58",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scoring_script = \"\"\"\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import mlflow\n",
    "from io import StringIO\n",
    "from mlflow.pyfunc.scoring_server import infer_and_parse_json_input, predictions_to_json\n",
    "from azure.storage.blob import BlobServiceClient, ContainerClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "import io\n",
    "import uuid\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    global input_schema\n",
    "    # \"model\" is the path of the mlflow artifacts when the model was registered. For automl\n",
    "    # models, this is generally \"mlflow-model\".\n",
    "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), \"model\")\n",
    "    model = mlflow.pyfunc.load_model(model_path)\n",
    "    input_schema = model.metadata.get_input_schema()\n",
    "\n",
    "\n",
    "def run(raw_data):\n",
    "    json_data = json.loads(raw_data)\n",
    "    if \"input_data\" not in json_data.keys():\n",
    "        raise Exception(\"Request must contain a top level key named 'input_data'\")\n",
    "\n",
    "    serving_input = json.dumps(json_data[\"input_data\"])\n",
    "    data = infer_and_parse_json_input(serving_input, input_schema)\n",
    "    predictions = model.predict(data)\n",
    "\n",
    "    # Logic for home-built model data collector\n",
    "    conn_str = os.getenv('conn_str')\n",
    "    container = os.getenv('container')\n",
    "    now = datetime.now()\n",
    "    df = pd.DataFrame(json_data['input_data']['data'], columns=json_data['input_data']['columns'])\n",
    "    df['timestamp'] = datetime.now()\n",
    "\n",
    "    container_client = ContainerClient.from_connection_string(conn_str, container)\n",
    "    blob_name = str(uuid.uuid4()) + \".csv\"\n",
    "    output = io.StringIO()\n",
    "    df.to_csv(output)\n",
    "    container_client.upload_blob(blob_name, output.getvalue(), overwrite=True)\n",
    "\n",
    "    result = StringIO()\n",
    "    predictions_to_json(predictions, result)\n",
    "    return result.getvalue()\n",
    "\"\"\"\n",
    "\n",
    "conda_yaml = \"\"\"\n",
    "channels:\n",
    "- conda-forge\n",
    "dependencies:\n",
    "- python=3.9.5\n",
    "- pip<=21.2.4\n",
    "- pip:\n",
    "  - mlflow==1.30.0\n",
    "  - cloudpickle==2.2.1\n",
    "  - psutil==5.8.0\n",
    "  - scikit-learn==0.24.2\n",
    "  - typing-extensions==4.5.0\n",
    "  - azureml-inference-server-http\n",
    "  - azure-storage-blob==12.16.0\n",
    "  - pandas==1.3.4\n",
    "name: mlflow-env\n",
    "\"\"\"\n",
    "\n",
    "with open('./score.py', 'w') as file:\n",
    "    file.write(scoring_script)\n",
    "    \n",
    "with open('./conda.yaml', 'w') as file:\n",
    "    file.write(conda_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b660ef9d-cb00-481f-84e7-b94ef80691b6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Train, evaluate, and register new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2eec5b3-45d1-4dd4-85ae-85849053fca4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Populate Delta table with sample data - Diabetes Dataset\n",
    "add_data_to_delta_table()\n",
    "\n",
    "# Load data from Delta table\n",
    "data = get_data_from_delta_table()\n",
    "\n",
    "# Establish connection to target Azure ML workspace\n",
    "ml_client = get_aml_client(subscription_id, resource_group, workspace)\n",
    "\n",
    "# Get the mlflow tracking URI associated with the AML workspace\n",
    "mlflow_tracking_uri = get_aml_mlflow_tracking_uri(ml_client)\n",
    "\n",
    "# Split loaded data into train/test subsets\n",
    "train_df, test_df = split_train_test_data(data, 0.85)\n",
    "\n",
    "# Train a new regression model and log to the target workspace. Experiment name/run name are used for organizational purposes and the run ID is returned for subsequent testing/registration\n",
    "run_id = train_regression_model('DEV-diabetes-model', 'sklearn-gbr', train_df, test_df, 'target', mlflow_tracking_uri)\n",
    "\n",
    "# Perform champion vs. challenger test to evaluate whether newly trained model is current best performer\n",
    "better_performer = evaluate_challenger_model(run_id, model_name, test_df, 'target')\n",
    "\n",
    "# If so, then add to the model registry\n",
    "if better_performer:\n",
    "    result = register_challenger_model(run_id, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aca0a7c6-a749-40dd-8c47-dbda0bd2c415",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Helper functions for model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "616d9336-0c0d-462f-96dd-fd4ffc560f88",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def check_if_endpoint_exists(endpoint_name, ml_client):\n",
    "    \"\"\"\n",
    "    Checks if an online endpoint exists in the ML model deployment environment. \n",
    "\n",
    "    This function checks if an online endpoint with the specified name exists in the ML deployment environment using the provided ML client. It returns True if the endpoint exists and False otherwise. \n",
    "\n",
    "    Args:\n",
    "    endpoint_name (str): The name of the online endpoint to check for existence.\n",
    "    ml_client (object): An instance of the ML client used to interact with the ML deployment environment. \n",
    "\n",
    "    Returns:\n",
    "    bool: True if the endpoint exists, False otherwise. \n",
    "    \"\"\"\n",
    "    try:\n",
    "        endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "        if endpoint:\n",
    "            print(f'Endpoint {endpoint_name} exists.')\n",
    "            return True\n",
    "        else:\n",
    "            print(f'Endpoint {endpoint_name} does not exist.')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "def create_endpoint(endpoint_name, endpoint_description, ml_client):\n",
    "    \"\"\"\n",
    "    Creates a new online endpoint for a machine learning model using the specified ML client. \n",
    "\n",
    "    This function creates a new online endpoint with the provided name and description using the provided ML client. The endpoint is configured with key-based authentication and system-assigned identity. The function prints a message indicating the creation of the endpoint. \n",
    "\n",
    "    Args:\n",
    "    endpoint_name (str): The name of the online endpoint to be created.\n",
    "    endpoint_description (str): A description for the online endpoint.\n",
    "    ml_client (object): An instance of the ML client used to interact with the ML deployment environment. \n",
    "\n",
    "    Returns:\n",
    "    None \n",
    "    \"\"\"\n",
    "    deployment_client = get_deploy_client(mlflow.get_tracking_uri())  \n",
    "    endpoint_config = {\n",
    "        \"auth_mode\": \"key\",\n",
    "        \"identity\": {\n",
    "            \"type\": \"system_assigned\"\n",
    "        }\n",
    "    }\n",
    "    endpoint_config_path = \"endpoint_config.json\"\n",
    "    with open(endpoint_config_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(endpoint_config))\n",
    "        \n",
    "    print(f'Creating endpoint {endpoint_name}')\n",
    "    endpoint = deployment_client.create_endpoint(\n",
    "        name=endpoint_name,\n",
    "        config={\"endpoint-config-file\": endpoint_config_path},\n",
    "    )\n",
    "    return\n",
    "\n",
    "def get_deployments(endpoint_name, ml_client):\n",
    "    \"\"\"\n",
    "    Retrieves the traffic allocation for a specific online endpoint using the provided ML client. \n",
    "\n",
    "    This function fetches the traffic allocation for a given online endpoint using the specified ML client. It returns the traffic allocation as a dictionary where each key-value pair represents the model version and its corresponding percentage of traffic. \n",
    "\n",
    "    Args:\n",
    "    endpoint_name (str): The name of the online endpoint for which to retrieve the traffic allocation.\n",
    "    ml_client (object): An instance of the ML client used to interact with the ML deployment environment. \n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the traffic allocation for the online endpoint, with model versions as keys and traffic percentages as values. \n",
    "    \"\"\"\n",
    "    endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "    return endpoint.traffic\n",
    "\n",
    "def get_staged_deployment(endpoint_name, ml_client):\n",
    "    \"\"\"  \n",
    "    Get the staged deployment of a given endpoint.  \n",
    "\n",
    "    This function retrieves the staged deployment with the highest traffic percentage  \n",
    "    for the specified endpoint. If no deployments are found, it returns None.\n",
    "\n",
    "    Parameters:  \n",
    "    endpoint_name (str): The name of the endpoint to retrieve the staged deployment from.  \n",
    "    ml_client (object): The Machine Learning client instance to interact with the API.  \n",
    "\n",
    "    Returns:  \n",
    "    str or None: The name of the staged deployment with the highest traffic percentage,  \n",
    "                 or None if no deployments are found.  \n",
    "    \"\"\"  \n",
    "    endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "    mirror_traffic = endpoint.mirror_traffic\n",
    "    if len(mirror_traffic.keys())==0:\n",
    "        return None\n",
    "    else:\n",
    "        staged_deployment = max(mirror_traffic, key=lambda k: mirror_traffic[k])\n",
    "        return staged_deployment\n",
    "\n",
    "def update_traffic(deployment_name, endpoint_name, traffic_percent):\n",
    "    \"\"\"\n",
    "    Updates the traffic allocation for a specific deployment within an online endpoint. \n",
    "\n",
    "    This function updates the traffic percentage for a given deployment within an online endpoint using the provided deployment_name, endpoint_name, and traffic_percent. The traffic allocation is updated using the deployment_client, and the function returns None. \n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment for which to update the traffic allocation.\n",
    "    endpoint_name (str): The name of the online endpoint containing the deployment.\n",
    "    traffic_percent (int): The new traffic percentage to allocate to the specified deployment. \n",
    "\n",
    "    Returns:\n",
    "    None \n",
    "    \"\"\"\n",
    "    deployment_client = get_deploy_client(mlflow.get_tracking_uri()) \n",
    "    traffic_config = {\"traffic\": {deployment_name: traffic_percent}}\n",
    "    traffic_config_path = \"traffic_config.json\"\n",
    "    \n",
    "    with open(traffic_config_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(traffic_config))\n",
    "        \n",
    "    print(f\"Updating traffic to {endpoint_name}\")\n",
    "    print(json.dumps(traffic_config))\n",
    "    deployment_client.update_endpoint(\n",
    "        endpoint=endpoint_name,\n",
    "        config={\"endpoint-config-file\": traffic_config_path},\n",
    "    )\n",
    "    return\n",
    "\n",
    "def update_mirror_traffic(deployment_name, endpoint_name, ml_client, traffic_percent):\n",
    "    \"\"\"\n",
    "    Update the mirror traffic percentage of a deployment in an online endpoint. \n",
    "\n",
    "    This function retrieves the online endpoint using the given endpoint_name, and updates the mirror traffic percentage\n",
    "    of the specified deployment_name within that endpoint. The new traffic percentage is set using the provided\n",
    "    traffic_percent parameter. \n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment for which the mirror traffic percentage needs to be updated.\n",
    "    endpoint_name (str): The name of the online endpoint containing the specified deployment.\n",
    "    ml_client (MLClient): An instance of MLClient used to manage and interact with the machine learning service.\n",
    "    traffic_percent (float): The new mirror traffic percentage to be assigned to the deployment. \n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"Updating mirror traffic at {endpoint_name}\")\n",
    "    print(json.dumps({deployment_name: traffic_percent}))\n",
    "    endpoint = ml_client.online_endpoints.get(endpoint_name)\n",
    "    endpoint.mirror_traffic = {deployment_name: traffic_percent}\n",
    "    result = ml_client.begin_create_or_update(endpoint).result()\n",
    "    return result\n",
    "    \n",
    "def create_initial_deployment(deployment_name, endpoint_name, model_name, model_version, ml_client, instance_type=\"Standard_F4s_v2\", instance_count=1):\n",
    "    \"\"\"\n",
    "    Create an initial deployment of a model to an online endpoint. \n",
    "\n",
    "    This function creates a deployment of a specified model and model version to an online endpoint using the provided\n",
    "    deployment_name and endpoint_name. The deployment is configured with the given instance_type and instance_count.\n",
    "    After the deployment is created, the traffic percentage is updated to 100%. \n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment to be created.\n",
    "    endpoint_name (str): The name of the online endpoint where the deployment will be created.\n",
    "    model_name (str): The name of the model to be deployed.\n",
    "    model_version (str): The version of the model to be deployed.\n",
    "    ml_client (MLClient): An instance of MLClient used to manage and interact with the machine learning service.\n",
    "    instance_type (str, optional): The instance type for the deployment. Defaults to \"Standard_F4s_v2\".\n",
    "    instance_count (int, optional): The number of instances for the deployment. Defaults to 1. \n",
    "\n",
    "    Returns:\n",
    "    bool: True if the deployment is created successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"Creating initial deployment. Endpoint: {endpoint_name}. Deployment: {deployment_name}.\")\n",
    "    deploy_config = {\n",
    "        \"instance_type\": instance_type,\n",
    "        \"instance_count\": instance_count\n",
    "    }\n",
    "    \n",
    "    deployment_config_path = \"deployment_config.json\"\n",
    "    \n",
    "    with open(deployment_config_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(deploy_config))\n",
    "        \n",
    "    deployment_client = get_deploy_client(mlflow.get_tracking_uri())\n",
    "    \n",
    "    tags = {'ModelName': model_name, 'ModelVersion': model_version}\n",
    "    \n",
    "    model = ml_client.models.get(name = model_name, version=model_version)\n",
    "    \n",
    "    environment = Environment(\n",
    "        conda_file=\"./conda.yaml\",\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    "    )\n",
    "\n",
    "    env_vars = {'conn_str': dbutils.secrets.get(scope=\"amlsecretscope\",key=\"storageconnstr\"), 'container': dbutils.secrets.get(scope=\"amlsecretscope\",key=\"container\")}\n",
    "\n",
    "    scale_settings = TargetUtilizationScaleSettings(\n",
    "        min_instances=1,\n",
    "        max_instances=6,\n",
    "        polling_interval=20,\n",
    "        target_utilization_percentage = 65\n",
    "    )\n",
    "\n",
    "    deployment = ManagedOnlineDeployment(\n",
    "        name=deployment_name,\n",
    "        endpoint_name=endpoint_name,\n",
    "        model=model,\n",
    "        environment=environment,\n",
    "        environment_variables=env_vars,\n",
    "        # scale_settings=scale_settings,\n",
    "        code_configuration=CodeConfiguration(\n",
    "            code=\".\",\n",
    "            scoring_script=\"score.py\"\n",
    "        ),\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "    )\n",
    "    \n",
    "    poller = ml_client.online_deployments.begin_create_or_update(deployment)\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    while poller.done() == False:\n",
    "        time.sleep(5)\n",
    "    \n",
    "    # Await completion here\n",
    "    \n",
    "#     deployment = deployment_client.create_deployment(\n",
    "#         name=deployment_name,\n",
    "#         endpoint=endpoint_name,\n",
    "#         model_uri=f\"models:/{model_name}/{model_version}\",\n",
    "#         config={\"deploy-config-file\": deployment_config_path},\n",
    "#     )\n",
    "    \n",
    "    update_traffic(deployment_name, endpoint_name, 100)\n",
    "    \n",
    "    return True\n",
    "\n",
    "def create_new_deployment(deployment_name, endpoint_name, model_name, model_version, ml_client, instance_type=\"Standard_F4s_v2\", instance_count=1):\n",
    "    \"\"\"\n",
    "    Create a new deployment of a model to an online endpoint and update the mirror traffic percentage. \n",
    "\n",
    "    This function creates a deployment of a specified model and model version to an online endpoint using the provided\n",
    "    deployment_name and endpoint_name. The deployment is configured with the given instance_type and instance_count.\n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment to be created.\n",
    "    endpoint_name (str): The name of the online endpoint where the deployment will be created.\n",
    "    model_name (str): The name of the model to be deployed.\n",
    "    model_version (str): The version of the model to be deployed.\n",
    "    ml_client (MLClient): An instance of MLClient used to manage and interact with the machine learning service.\n",
    "    instance_type (str, optional): The instance type for the deployment. Defaults to \"Standard_F4s_v2\".\n",
    "    instance_count (int, optional): The number of instances for the deployment. Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"Creating new deployment. Endpoint: {endpoint_name}. Deployment: {deployment_name}.\")\n",
    "    deploy_config = {\n",
    "        \"instance_type\": instance_type,\n",
    "        \"instance_count\": instance_count\n",
    "    }\n",
    "        \n",
    "    deployment_config_path = \"deployment_config.json\"\n",
    "    \n",
    "    with open(deployment_config_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(deploy_config))\n",
    "        \n",
    "#     deployment_client = get_deploy_client(mlflow.get_tracking_uri()) \n",
    "    \n",
    "#     deployment = deployment_client.create_deployment(\n",
    "#         name=deployment_name,\n",
    "#         endpoint=endpoint_name,\n",
    "#         model_uri=f\"models:/{model_name}/{model_version}\",\n",
    "#         config={\"deploy-config-file\": deployment_config_path},\n",
    "#     )\n",
    "\n",
    "    model = ml_client.models.get(name = model_name, version=model_version)\n",
    "    \n",
    "    environment = Environment(\n",
    "        conda_file=\"./conda.yaml\",\n",
    "        image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    "    )\n",
    "\n",
    "    env_vars = {'conn_str': dbutils.secrets.get(scope=\"amlsecretscope\",key=\"storageconnstr\"), 'container': dbutils.secrets.get(scope=\"amlsecretscope\",key=\"container\")}\n",
    "\n",
    "    scale_settings = TargetUtilizationScaleSettings(\n",
    "        min_instances=1,\n",
    "        max_instances=6,\n",
    "        polling_interval=20,\n",
    "        target_utilization_percentage = 65\n",
    "    )\n",
    "\n",
    "    deployment = ManagedOnlineDeployment(\n",
    "        name=deployment_name,\n",
    "        endpoint_name=endpoint_name,\n",
    "        model=model,\n",
    "        environment=environment,\n",
    "        environment_variables=env_vars,\n",
    "        # scale_settings=scale_settings,\n",
    "        code_configuration=CodeConfiguration(\n",
    "            code=\".\",\n",
    "            scoring_script=\"score.py\"\n",
    "        ),\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "    )\n",
    "    \n",
    "    poller = ml_client.online_deployments.begin_create_or_update(deployment)\n",
    "    \n",
    "    while poller.done() == False:\n",
    "        time.sleep(5)\n",
    "    \n",
    "    # Await completion here\n",
    "\n",
    "    return\n",
    "    \n",
    "def test_new_deployment(deployment_name, endpoint_name, test_df, target):\n",
    "    \"\"\"\n",
    "    Test a new deployment on an online endpoint using a sample data frame. \n",
    "\n",
    "    This function tests the specified deployment_name on an online endpoint using the provided test_df data frame.\n",
    "    It generates a sample request using the test_df (excluding the target column) and sends it to the deployment.\n",
    "    The function returns True if the number of scored data points matches the length of the test_df, otherwise, it\n",
    "    returns False. \n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment to be tested.\n",
    "    endpoint_name (str): The name of the online endpoint where the deployment is located.\n",
    "    test_df (pd.DataFrame): A pandas data frame containing the data to be used for testing the deployment.\n",
    "    target (str): The name of the target column in the test_df that should be excluded from the input data. \n",
    "\n",
    "    Returns:\n",
    "    bool: True if the test is successful and the number of scored data points matches the length of the test_df,\n",
    "    False otherwise.\n",
    "    \"\"\"\n",
    "    sample_request = {\"input_data\": test_df.drop(columns=[target]).to_dict(orient='split')}\n",
    "    sample_request_path = \"sample_data.json\"\n",
    "    \n",
    "    with open(sample_request_path, \"w\") as outfile:\n",
    "        outfile.write(json.dumps(sample_request))\n",
    "        \n",
    "    print(f\"Testing deployment '{deployment_name}' with {str(len(test_df))} datapoints.\")\n",
    "        \n",
    "    result = ml_client.online_endpoints.invoke(\n",
    "        endpoint_name=endpoint_name,\n",
    "        deployment_name=deployment_name,\n",
    "        request_file=sample_request_path,\n",
    "    )\n",
    "    try:\n",
    "        scored_data = json.loads(result)\n",
    "        print(f\"{str(len(scored_data))} predictions returned.\")\n",
    "        print(result)\n",
    "        print(scored_data)\n",
    "        return True\n",
    "        if len(scored_data)==len(test_df):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "def get_current_deployment_name(deployments, model_name):\n",
    "    \"\"\"\n",
    "    Get the current active deployment name for a given model from a dictionary of deployments. \n",
    "\n",
    "    This function takes a dictionary of deployments and the model_name as input, and returns the name of the current\n",
    "    active deployment for the specified model. If there are no deployments, the function returns None. If there are\n",
    "    deployments, the function returns the name of the deployment with the highest traffic percentage. \n",
    "\n",
    "    Args:\n",
    "    deployments (dict): A dictionary containing deployment names as keys and their corresponding traffic percentages as values.\n",
    "    model_name (str): The name of the model for which the current active deployment name is required. \n",
    "\n",
    "    Returns:\n",
    "    str: The name of the current active deployment for the specified model, or None if there are no deployments.\n",
    "    \"\"\"\n",
    "    if len(deployments.keys())==0:\n",
    "        return None\n",
    "    else:\n",
    "        active_deployment = max(deployments, key=lambda k: deployments[k])\n",
    "    return active_deployment\n",
    " \n",
    "def get_new_deployment_name(deployments, model_name):\n",
    "    \"\"\"\n",
    "    Get a new deployment name for a given model from a dictionary of deployments. \n",
    "\n",
    "    This function takes a dictionary of deployments and the model_name as input, and generates a new deployment name\n",
    "    for the specified model. If there are no deployments, the function creates a deployment name with a 'BLUE' prefix.\n",
    "    If there are existing deployments, it checks the prefix of the current active deployment and creates a new deployment\n",
    "    name with the opposite color prefix (either 'BLUE' or 'GREEN'). \n",
    "\n",
    "    Args:\n",
    "    deployments (dict): A dictionary containing deployment names as keys and their corresponding traffic percentages as values.\n",
    "    model_name (str): The name of the model for which the new deployment name is required. \n",
    "\n",
    "    Returns:\n",
    "    str: A new deployment name for the specified model with either a 'BLUE' or 'GREEN' prefix, depending on the current active deployment.\n",
    "    \"\"\"\n",
    "    if len(deployments.keys())==0:\n",
    "        deployment_name = f'BLUE-{model_name}'\n",
    "    else:\n",
    "        active_deployment = max(deployments, key=lambda k: deployments[k])\n",
    "        if 'blue' in active_deployment.lower():\n",
    "            deployment_name = f'GREEN-{model_name}'\n",
    "        else:\n",
    "            deployment_name = f'BLUE-{model_name}'\n",
    "    return deployment_name.lower()\n",
    "\n",
    "def remove_current_deployment(deployment_name, endpoint_name, ml_client):\n",
    "    \"\"\"\n",
    "    Remove the current deployment from an online endpoint. \n",
    "\n",
    "    This function removes the specified deployment_name from the online endpoint using the provided ml_client. The\n",
    "    function begins the delete operation but does not wait for it to complete. \n",
    "\n",
    "    Args:\n",
    "    deployment_name (str): The name of the deployment to be removed.\n",
    "    endpoint_name (str): The name of the online endpoint where the deployment is located.\n",
    "    ml_client (MLClient): An instance of MLClient used to manage and interact with the machine learning service. \n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    print(f\"Removing deployment {deployment_name} from endpoint {endpoint_name}\")\n",
    "    ml_client.online_deployments.begin_delete(deployment_name, endpoint_name)\n",
    "    return\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b07aa6c-6d9c-4d30-a490-b4b037c6f4a2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Deploy newly trained model using \"safe rollout\" pattern\n",
    "\n",
    "[Details about 'safe rollout' pattern](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-safely-rollout-online-endpoints?view=azureml-api-2&tabs=python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdbe14b0-67f9-4c51-af0a-872b0bbe0bf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# If new model performs better than existing champion (or if no champion exists...)\n",
    "if better_performer:\n",
    "    \n",
    "    # Check if endpoint exists\n",
    "    endpoint_exists = check_if_endpoint_exists(endpoint_name, ml_client)\n",
    "    \n",
    "    # If endpoint does not exist create it\n",
    "    if not endpoint_exists:\n",
    "        create_endpoint(endpoint_name, endpoint_description, ml_client)\n",
    "        \n",
    "    # Get all deployments to current endpoint\n",
    "    deployments = get_deployments(endpoint_name, ml_client)\n",
    "    \n",
    "    # If no deployments exist on current endpoint, create a deployment and route 100% of traffic to it\n",
    "    if len(deployments.keys())==0:\n",
    "        \n",
    "        # Get deployment name (BLUE + model_name)\n",
    "        deployment_name = get_new_deployment_name(deployments, model_name)\n",
    "        \n",
    "        # Create deployment with 0% traffic allocation\n",
    "        create_initial_deployment(deployment_name, endpoint_name, model_name, result.version, ml_client)\n",
    "        \n",
    "        # Test model endpoint with holdout data (smoke test)\n",
    "        test_result = test_new_deployment(deployment_name, endpoint_name, test_df, 'target')\n",
    "        \n",
    "        # If model passes smoke test, route 100% of traffic to the endpoint\n",
    "        if test_result:\n",
    "            update_traffic(deployment_name, endpoint_name, 100)\n",
    "\n",
    "    # Alternatively, a model has already been deployed to this endpoint and we need to update\n",
    "    else:\n",
    "        # Get name of current deployment\n",
    "        active_deployment_name = get_current_deployment_name(deployments, model_name)\n",
    "        \n",
    "        # Get name of new deployment (will be associated with open slot [blue or green])\n",
    "        deployment_name = get_new_deployment_name(deployments, model_name)\n",
    "        \n",
    "        # Create deployment with 0% traffic allocation\n",
    "        create_new_deployment(deployment_name, endpoint_name, model_name, result.version, ml_client)\n",
    "        \n",
    "        # Test model endpoint with holdout data (smoke test)\n",
    "        test_result = test_new_deployment(deployment_name, endpoint_name, test_df, 'target')\n",
    "        \n",
    "        # If model passes smoke test, mirror 10% of all traffic to endpoint\n",
    "        if test_result:\n",
    "            update_mirror_traffic(deployment_name, endpoint_name, ml_client, 10)\n",
    "            \n",
    "# Manual update to route all traffic to new endpoint as part of a separate process..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d63e9fde-822d-4c62-af76-9c302bb3877c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Test your endpoint\n",
    "\n",
    "In the Azure ML Studio UI you can submit data to your endpoint for manual testing. Try using the data below:\n",
    "```\n",
    "{\n",
    "  \"input_data\": {\"index\": [0,1,2],\n",
    "  \"columns\": [\"age\", \"sex\", \"bmi\", \"bp\", \"s1\", \"s2\", \"s3\", \"s4\", \"s5\", \"s6\"],\n",
    "  \"data\": [[0.00538306037424807,\n",
    "    -0.044641636506989,\n",
    "    -0.0482406250171634,\n",
    "    -0.0125563519424068,\n",
    "    0.00118294589619092,\n",
    "    -0.00663740127664067,\n",
    "    0.0633666506664982,\n",
    "    -0.0394933828740919,\n",
    "    -0.0514005352605825,\n",
    "    -0.0590671943081523],\n",
    "   [0.0126481372762872,\n",
    "    0.0506801187398187,\n",
    "    0.000260918307477141,\n",
    "    -0.0114087283893043,\n",
    "    0.0397096259258226,\n",
    "    0.0572448849284239,\n",
    "    -0.0397192078479398,\n",
    "    0.0560805201945126,\n",
    "    0.024052583226893,\n",
    "    0.0320591578182113],\n",
    "   [0.0380759064334241,\n",
    "    0.0506801187398187,\n",
    "    0.00888341489852436,\n",
    "    0.0425295791573734,\n",
    "    -0.0428475455662452,\n",
    "    -0.0210422305189592,\n",
    "    -0.0397192078479398,\n",
    "    -0.00259226199818282,\n",
    "    -0.0181182673078967,\n",
    "    0.00720651632920303]]}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "AML_Train_Register_Deploy",
   "notebookOrigID": 1031372175797327,
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
