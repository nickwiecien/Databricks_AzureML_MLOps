trigger:
  branches:
    include:
    - main
  paths:
    include:
    - /

variables:
- group: aml_dbx_variables
  
pool:  
  vmImage: 'ubuntu-latest'  
  
steps:  
- task: UsePythonVersion@0  
  inputs:  
    versionSpec: '3.8'  
    addToPath: true  
  
- task: AzureCLI@2  
  displayName: 'Submit and Run Databricks Job (Train, Evaluate, Register)'
  env:
      DATABRICKS_HOST: $(DBX_WORKSPACE)
      DATABRICKS_TOKEN: $(DBX_PAT)
  inputs:  
    azureSubscription: '$(SUBSCRIPTION_SVC_CONNECTION)'  
    scriptType: 'bash'  
    scriptLocation: 'inlineScript'  
    inlineScript: |  

      # Install Databricks CLI
      pip install databricks-cli
  
      # Upload notebook to target workspace  
      databricks workspace import $NOTEBOOK_PATH $NOTEBOOK_PATH_DBX -l PYTHON -f JUPYTER -o

      # Remove existing training job
      databricks jobs list --output json | jq '.jobs[] | select(.settings.name == "TrainingRun") | .job_id' | xargs -n 1 databricks jobs delete --job-id

      # Create training job definition
      JOB_ID=$(databricks jobs create --json '{
        "name": "TrainingRun",
        "existing_cluster_id": "$(DBX_CLUSTER)",
        "timeout_seconds": 3600,
        "max_retries": 1,
        "notebook_task": {
          "notebook_path": "$(NOTEBOOK_PATH_DBX)",
          "base_parameters": {"subscription_id": "$(SUBSCRIPTION_ID)", "resource_group": "$(RESOURCE_GROUP)", "workspace": "$(AML_WORKSPACE_NAME)", "model_name": "DEV-diabetes-model", "endpoint_name": "DEV-diabetes-endpoint2", "endpoint_description": "Regression model for predicting disease pregression"}
        }
      }' | jq '.job_id')

      # Submit run
      RUN_ID=$(databricks jobs run-now --job-id $JOB_ID | jq '.run_id')

      echo $RUN_ID

      # Wait until done
      job_status="PENDING"
      while [ $job_status = "RUNNING" ] || [ $job_status = "PENDING" ]
      do
        sleep 2
        job_status=$(databricks runs get --run-id $RUN_ID | jq -r '.state.life_cycle_state')
        echo Status $job_status
      done